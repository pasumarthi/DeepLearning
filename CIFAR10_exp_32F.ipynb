{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_exp_32F.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/pasumarthi/DeepLearning/blob/master/CIFAR10_exp_32F.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "k2iqHIWjXxAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28fa9f74-38f0-43b0-bdc3-5859c5b228c5"
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "#The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam,SGD"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jD6uKk91YRpF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StLvvuNet2cI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "031ac4ce-355b-4413-be5c-7cf8020711c7"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "print( os.getcwd() )\n",
        "print( os.listdir() )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['datalab', '.cache', 'CIFAR10_Batch419-0.606.hdf5', 'CIFAR10_Batch421-0.611.hdf5', '.rnd', 'CIFAR10_Batch425-0.638.hdf5', '.config', 'CIFAR10_Batch403-0.485.hdf5', '.local', '.nv', 'CIFAR10_Batch409-0.564.hdf5', '.ipython', 'CIFAR10_Batch415-0.581.hdf5', '.keras', '.forever']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "txo319eCYXb6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "layers = 20\n",
        "num_filter = 32\n",
        "compression = 0.6\n",
        "dropout_rate = 0.3\n",
        "name='CIFAR10_Batch4'\n",
        "data_augmentation = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pj9R8LcgYchP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9e0d04f-8715-4a4e-b5d9-4be0bd0826a8"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "print(img_height, img_width, channel)\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "#print(x_train.shape[1:])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32 32 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OaHiPfLyYxeX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2, layers=6):\n",
        "    global compression\n",
        "    print(layers)\n",
        "    temp = input\n",
        "    for _ in range(layers):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EvvB60RoZUFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AXq7bmpzZVT4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = MaxPooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wv1UFhmZaGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e39ac520-a7a9-4d0b-acf6-f33f8e898413"
      },
      "cell_type": "code",
      "source": [
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "First_Conv2D = Conv2D(num_filter*2, (3,3),use_bias=False )(input)\n",
        "Second_Con2D =Conv2D(num_filter*4,(7,1),use_bias=False)(First_Conv2D)\n",
        "Third_Con2D=Conv2D(num_filter, (1,7), use_bias = False)(Second_Con2D)\n",
        "Forth_Con2D=Conv2D(num_filter, (1,1), use_bias = False)(Third_Con2D)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate,layers=3)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate,layers=9)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate,layers=9)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate=12)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "9\n",
            "9\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsBAcKAOZsMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5863
        },
        "outputId": "b704ab77-7c42-4364-885d-e4d439c0603a"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 30, 30, 64)   1728        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 30, 30, 64)   256         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 30, 30, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 30, 30, 32)   18432       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 30, 30, 32)   0           conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 30, 30, 96)   0           conv2d_74[0][0]                  \n",
            "                                                                 dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 30, 30, 96)   384         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 30, 30, 96)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 30, 30, 32)   27648       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 30, 30, 32)   0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 30, 30, 128)  0           concatenate_52[0][0]             \n",
            "                                                                 dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 30, 30, 128)  512         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 30, 30, 128)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 30, 30, 32)   36864       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 30, 30, 32)   0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 30, 30, 160)  0           concatenate_53[0][0]             \n",
            "                                                                 dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 30, 30, 160)  640         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 30, 30, 160)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 30, 30, 19)   3040        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 30, 30, 19)   0           conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 15, 15, 19)   0           dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 15, 15, 19)   76          average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 15, 15, 19)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 15, 15, 32)   5472        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 15, 15, 32)   0           conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 15, 15, 51)   0           average_pooling2d_7[0][0]        \n",
            "                                                                 dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 15, 15, 51)   204         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 15, 15, 51)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 15, 15, 32)   14688       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 15, 15, 32)   0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 15, 15, 83)   0           concatenate_55[0][0]             \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 15, 15, 83)   332         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 15, 15, 83)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 15, 15, 32)   23904       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 15, 15, 32)   0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 15, 15, 115)  0           concatenate_56[0][0]             \n",
            "                                                                 dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 15, 15, 115)  460         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 15, 15, 115)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 15, 15, 32)   33120       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 15, 15, 32)   0           conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 15, 15, 147)  0           concatenate_57[0][0]             \n",
            "                                                                 dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 15, 15, 147)  588         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 15, 15, 147)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 15, 15, 32)   42336       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 15, 15, 32)   0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 15, 15, 179)  0           concatenate_58[0][0]             \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 15, 15, 179)  716         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 15, 15, 179)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 15, 15, 32)   51552       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 15, 15, 32)   0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 15, 15, 211)  0           concatenate_59[0][0]             \n",
            "                                                                 dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 15, 15, 211)  844         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 15, 15, 211)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 15, 15, 32)   60768       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 15, 15, 32)   0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 15, 15, 243)  0           concatenate_60[0][0]             \n",
            "                                                                 dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 15, 15, 243)  972         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 15, 15, 243)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 15, 15, 32)   69984       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 15, 15, 32)   0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 15, 15, 275)  0           concatenate_61[0][0]             \n",
            "                                                                 dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 15, 15, 275)  1100        concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 15, 15, 275)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 15, 15, 32)   79200       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 15, 15, 32)   0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 15, 15, 307)  0           concatenate_62[0][0]             \n",
            "                                                                 dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 15, 15, 307)  1228        concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 15, 15, 307)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 15, 15, 19)   5833        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 15, 15, 19)   0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 7, 7, 19)     0           dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 19)     76          average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 19)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 7, 7, 32)     5472        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 7, 7, 32)     0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 7, 7, 51)     0           average_pooling2d_8[0][0]        \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 7, 7, 51)     204         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 7, 7, 51)     0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 7, 7, 32)     14688       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 7, 7, 32)     0           conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 7, 7, 83)     0           concatenate_64[0][0]             \n",
            "                                                                 dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 7, 7, 83)     332         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 7, 7, 83)     0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 7, 7, 32)     23904       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 7, 7, 32)     0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 7, 7, 115)    0           concatenate_65[0][0]             \n",
            "                                                                 dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 7, 7, 115)    460         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 7, 7, 115)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 7, 7, 32)     33120       activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 7, 7, 32)     0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 7, 7, 147)    0           concatenate_66[0][0]             \n",
            "                                                                 dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 7, 7, 147)    588         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 7, 7, 147)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 7, 7, 32)     42336       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 7, 7, 32)     0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 7, 7, 179)    0           concatenate_67[0][0]             \n",
            "                                                                 dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 7, 7, 179)    716         concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 7, 7, 179)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 7, 7, 32)     51552       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 7, 7, 32)     0           conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 7, 7, 211)    0           concatenate_68[0][0]             \n",
            "                                                                 dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 7, 7, 211)    844         concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 7, 7, 211)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 7, 7, 32)     60768       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 7, 7, 32)     0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 7, 7, 243)    0           concatenate_69[0][0]             \n",
            "                                                                 dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 7, 7, 243)    972         concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 7, 7, 243)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 7, 7, 32)     69984       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 7, 7, 32)     0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 7, 7, 275)    0           concatenate_70[0][0]             \n",
            "                                                                 dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 7, 7, 275)    1100        concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 7, 7, 275)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 7, 7, 32)     79200       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 7, 7, 32)     0           conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 7, 7, 307)    0           concatenate_71[0][0]             \n",
            "                                                                 dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 7, 7, 307)    1228        concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 7, 7, 307)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 7, 7, 19)     5833        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 7, 7, 19)     0           conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 3, 3, 19)     0           dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 19)     76          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 19)     0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 3, 3, 32)     5472        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 3, 3, 32)     0           conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 3, 3, 51)     0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 51)     204         concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 51)     0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 3, 3, 32)     14688       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 3, 3, 32)     0           conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 3, 3, 83)     0           concatenate_73[0][0]             \n",
            "                                                                 dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 83)     332         concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 83)     0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 3, 3, 32)     23904       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 3, 3, 32)     0           conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 3, 3, 115)    0           concatenate_74[0][0]             \n",
            "                                                                 dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 115)    460         concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 115)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 3, 3, 32)     33120       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 3, 3, 32)     0           conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 3, 3, 147)    0           concatenate_75[0][0]             \n",
            "                                                                 dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 147)    588         concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 147)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 3, 3, 32)     42336       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 3, 3, 32)     0           conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 3, 3, 179)    0           concatenate_76[0][0]             \n",
            "                                                                 dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 179)    716         concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 179)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 3, 3, 32)     51552       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 3, 3, 32)     0           conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 3, 3, 211)    0           concatenate_77[0][0]             \n",
            "                                                                 dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 211)    844         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 211)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 211)    0           activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 211)          0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           2120        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,052,670\n",
            "Trainable params: 1,043,644\n",
            "Non-trainable params: 9,026\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "utriiGgPKOTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4WK1QoDLpAWU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_schedule = [10, 20, 30] # epoch_step\n",
        "def schedule(epoch_idx):\n",
        "    if (epoch_idx + 1) < lr_schedule[0]:\n",
        "        return 0.1\n",
        "    elif (epoch_idx + 1) < lr_schedule[1]:\n",
        "        return 0.02 # lr_decay_ratio = 0.2\n",
        "    elif (epoch_idx + 1) < lr_schedule[2]:\n",
        "        return 0.004\n",
        "    return 0.0008"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o93hgJk_oB1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.callbacks as callbacks\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "save_c = callbacks.ModelCheckpoint(name + '{epoch:02d}-{val_acc:.3f}.hdf5', monitor=\"val_acc\", save_best_only=True,save_weights_only=True,mode='max',period=2)\n",
        "lrs = LearningRateScheduler(schedule=schedule)\n",
        "callbacks_list = [save_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ytc6Tq-7Rea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79f2245b-f16f-424b-dc64-1633f481e27d"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "data_augmentation=True\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "    "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FX_rrbQF0iHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d0d61e21-e2ea-401b-a617-8a7e53a779d1"
      },
      "cell_type": "code",
      "source": [
        "#train_datagen=datagen.fit(x_train, augment=True)\n",
        "#validate_datagen=datagen.fit(x_test, augment=True)\n",
        "# compute quantities required for featurewise normalization\n",
        "#datagen.fit(x_train, augment=True)\n",
        "#datagen.fit(x_test, augment=True)\n",
        "#print(x_train.shape[0], 'train samples')\n",
        "#print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CycpTkaNwbP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1582
        },
        "outputId": "e83a4b14-1cb5-41e4-a79c-10e3607a4a09"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size= 128),\n",
        "          callbacks=[save_c],\n",
        "          epochs=45,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test)\n",
        "          )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
            "Epoch 1/45\n",
            "373/391 [===========================>..] - ETA: 6s - loss: 1.7065 - acc: 0.3790"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 160s 409ms/step - loss: 1.6940 - acc: 0.3833 - val_loss: 3.1636 - val_acc: 0.2991\n",
            "Epoch 2/45\n",
            "391/391 [==============================] - 148s 380ms/step - loss: 1.3077 - acc: 0.5246 - val_loss: 3.9369 - val_acc: 0.2759\n",
            "Epoch 3/45\n",
            " 37/391 [=>............................] - ETA: 2:09 - loss: 1.2407 - acc: 0.5608"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 149s 380ms/step - loss: 1.1493 - acc: 0.5844 - val_loss: 2.5054 - val_acc: 0.4129\n",
            "Epoch 4/45\n",
            "328/391 [========================>.....] - ETA: 22s - loss: 1.0516 - acc: 0.6230"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 377ms/step - loss: 1.0465 - acc: 0.6256 - val_loss: 1.9024 - val_acc: 0.4844\n",
            "Epoch 5/45\n",
            "391/391 [==============================] - 147s 377ms/step - loss: 0.9748 - acc: 0.6527 - val_loss: 2.2882 - val_acc: 0.4451\n",
            "Epoch 6/45\n",
            " 27/391 [=>............................] - ETA: 2:10 - loss: 0.9388 - acc: 0.6612"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 377ms/step - loss: 0.9090 - acc: 0.6774 - val_loss: 2.6403 - val_acc: 0.4762\n",
            "Epoch 7/45\n",
            "325/391 [=======================>......] - ETA: 23s - loss: 0.8635 - acc: 0.6935"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.8614 - acc: 0.6941 - val_loss: 1.6304 - val_acc: 0.5489\n",
            "Epoch 8/45\n",
            "391/391 [==============================] - 148s 378ms/step - loss: 0.8143 - acc: 0.7129 - val_loss: 1.8197 - val_acc: 0.5703\n",
            "Epoch 9/45\n",
            " 26/391 [>.............................] - ETA: 2:10 - loss: 0.8063 - acc: 0.7194"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.7714 - acc: 0.7282 - val_loss: 1.5098 - val_acc: 0.6070\n",
            "Epoch 10/45\n",
            "323/391 [=======================>......] - ETA: 24s - loss: 0.7468 - acc: 0.7389"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.7444 - acc: 0.7394 - val_loss: 2.5681 - val_acc: 0.5046\n",
            "Epoch 11/45\n",
            "391/391 [==============================] - 148s 379ms/step - loss: 0.7093 - acc: 0.7519 - val_loss: 1.5301 - val_acc: 0.6547\n",
            "Epoch 12/45\n",
            " 25/391 [>.............................] - ETA: 2:10 - loss: 0.6762 - acc: 0.7616"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.6864 - acc: 0.7587 - val_loss: 1.3944 - val_acc: 0.6438\n",
            "Epoch 13/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.6607 - acc: 0.7699"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.6604 - acc: 0.7694 - val_loss: 1.6244 - val_acc: 0.6310\n",
            "Epoch 14/45\n",
            "391/391 [==============================] - 148s 379ms/step - loss: 0.6402 - acc: 0.7787 - val_loss: 1.1386 - val_acc: 0.6920\n",
            "Epoch 15/45\n",
            " 25/391 [>.............................] - ETA: 2:10 - loss: 0.6165 - acc: 0.7803"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 149s 380ms/step - loss: 0.6210 - acc: 0.7836 - val_loss: 1.2573 - val_acc: 0.6864\n",
            "Epoch 16/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.6046 - acc: 0.7883"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.6020 - acc: 0.7894 - val_loss: 1.1829 - val_acc: 0.6900\n",
            "Epoch 17/45\n",
            "391/391 [==============================] - 148s 379ms/step - loss: 0.5872 - acc: 0.7962 - val_loss: 1.5673 - val_acc: 0.6534\n",
            "Epoch 18/45\n",
            " 25/391 [>.............................] - ETA: 2:10 - loss: 0.5841 - acc: 0.7941"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.5706 - acc: 0.8017 - val_loss: 1.3202 - val_acc: 0.6686\n",
            "Epoch 19/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.5616 - acc: 0.8056"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.5597 - acc: 0.8059 - val_loss: 0.8997 - val_acc: 0.7615\n",
            "Epoch 20/45\n",
            "391/391 [==============================] - 148s 380ms/step - loss: 0.5511 - acc: 0.8090 - val_loss: 1.0087 - val_acc: 0.7318\n",
            "Epoch 21/45\n",
            " 25/391 [>.............................] - ETA: 2:11 - loss: 0.5195 - acc: 0.8184"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 147s 377ms/step - loss: 0.5312 - acc: 0.8161 - val_loss: 1.3200 - val_acc: 0.6670\n",
            "Epoch 22/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.5209 - acc: 0.8183"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 147s 376ms/step - loss: 0.5239 - acc: 0.8170 - val_loss: 1.2398 - val_acc: 0.7057\n",
            "Epoch 23/45\n",
            "391/391 [==============================] - 147s 376ms/step - loss: 0.5186 - acc: 0.8200 - val_loss: 0.8141 - val_acc: 0.7709\n",
            "Epoch 24/45\n",
            " 25/391 [>.............................] - ETA: 2:11 - loss: 0.4801 - acc: 0.8353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.5043 - acc: 0.8259 - val_loss: 1.0375 - val_acc: 0.7345\n",
            "Epoch 25/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.4973 - acc: 0.8278"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 147s 377ms/step - loss: 0.4946 - acc: 0.8282 - val_loss: 1.1947 - val_acc: 0.7200\n",
            "Epoch 26/45\n",
            "391/391 [==============================] - 147s 377ms/step - loss: 0.4925 - acc: 0.8301 - val_loss: 1.0518 - val_acc: 0.7508\n",
            "Epoch 27/45\n",
            " 25/391 [>.............................] - ETA: 2:11 - loss: 0.4842 - acc: 0.8313"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.4797 - acc: 0.8325 - val_loss: 1.0119 - val_acc: 0.7655\n",
            "Epoch 28/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.4712 - acc: 0.8378"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.4749 - acc: 0.8366 - val_loss: 0.8242 - val_acc: 0.7788\n",
            "Epoch 29/45\n",
            "391/391 [==============================] - 148s 379ms/step - loss: 0.4672 - acc: 0.8395 - val_loss: 0.8686 - val_acc: 0.7863\n",
            "Epoch 30/45\n",
            " 25/391 [>.............................] - ETA: 2:11 - loss: 0.4596 - acc: 0.8428"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.4616 - acc: 0.8397 - val_loss: 0.7460 - val_acc: 0.7975\n",
            "Epoch 31/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.4554 - acc: 0.8408"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.4544 - acc: 0.8408 - val_loss: 1.0960 - val_acc: 0.7269\n",
            "Epoch 32/45\n",
            "391/391 [==============================] - 148s 378ms/step - loss: 0.4458 - acc: 0.8441 - val_loss: 0.8612 - val_acc: 0.7778\n",
            "Epoch 33/45\n",
            " 25/391 [>.............................] - ETA: 2:11 - loss: 0.4336 - acc: 0.8481"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.4446 - acc: 0.8460 - val_loss: 1.8153 - val_acc: 0.6464\n",
            "Epoch 34/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.4309 - acc: 0.8509"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.4323 - acc: 0.8502 - val_loss: 0.8767 - val_acc: 0.7800\n",
            "Epoch 35/45\n",
            "391/391 [==============================] - 147s 377ms/step - loss: 0.4282 - acc: 0.8510 - val_loss: 0.8817 - val_acc: 0.7915\n",
            "Epoch 36/45\n",
            " 25/391 [>.............................] - ETA: 2:09 - loss: 0.4453 - acc: 0.8409"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 378ms/step - loss: 0.4263 - acc: 0.8505 - val_loss: 0.6222 - val_acc: 0.8364\n",
            "Epoch 37/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.4193 - acc: 0.8547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 148s 379ms/step - loss: 0.4188 - acc: 0.8545 - val_loss: 1.0798 - val_acc: 0.7581\n",
            "Epoch 38/45\n",
            "391/391 [==============================] - 148s 379ms/step - loss: 0.4228 - acc: 0.8529 - val_loss: 0.7021 - val_acc: 0.8162\n",
            "Epoch 39/45\n",
            " 25/391 [>.............................] - ETA: 2:12 - loss: 0.3840 - acc: 0.8675"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 149s 381ms/step - loss: 0.4083 - acc: 0.8576 - val_loss: 0.7097 - val_acc: 0.8135\n",
            "Epoch 40/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.4088 - acc: 0.8590"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 149s 382ms/step - loss: 0.4089 - acc: 0.8591 - val_loss: 1.0397 - val_acc: 0.7727\n",
            "Epoch 41/45\n",
            "391/391 [==============================] - 149s 381ms/step - loss: 0.4014 - acc: 0.8614 - val_loss: 0.6293 - val_acc: 0.8428\n",
            "Epoch 42/45\n",
            " 25/391 [>.............................] - ETA: 2:11 - loss: 0.3876 - acc: 0.8656"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 149s 382ms/step - loss: 0.3975 - acc: 0.8628 - val_loss: 0.8270 - val_acc: 0.8041\n",
            "Epoch 43/45\n",
            "322/391 [=======================>......] - ETA: 24s - loss: 0.3940 - acc: 0.8617"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 150s 383ms/step - loss: 0.3937 - acc: 0.8617 - val_loss: 1.0967 - val_acc: 0.7566\n",
            "Epoch 44/45\n",
            "391/391 [==============================] - 150s 384ms/step - loss: 0.3945 - acc: 0.8635 - val_loss: 0.6852 - val_acc: 0.8203\n",
            "Epoch 45/45\n",
            " 25/391 [>.............................] - ETA: 2:10 - loss: 0.3571 - acc: 0.8681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 150s 384ms/step - loss: 0.3831 - acc: 0.8668 - val_loss: 1.3919 - val_acc: 0.7200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3576b57630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "fH3wX-JidYcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "95735a6f-0469-4e94-a8ba-7f3d39340bc6"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 13s 1ms/step\n",
            "Test loss: 1.3918771629333495\n",
            "Test accuracy: 0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d_FBNQ91uN6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "60b19cc6-5ef1-4a69-a0fa-5bbd7f9f783e"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CIFAR10_Batch402-0.276.hdf5  CIFAR10_Batch420-0.732.hdf5\r\n",
            "CIFAR10_Batch403-0.485.hdf5  CIFAR10_Batch421-0.611.hdf5\r\n",
            "CIFAR10_Batch404-0.484.hdf5  CIFAR10_Batch424-0.735.hdf5\r\n",
            "CIFAR10_Batch408-0.570.hdf5  CIFAR10_Batch425-0.638.hdf5\r\n",
            "CIFAR10_Batch409-0.564.hdf5  CIFAR10_Batch426-0.751.hdf5\r\n",
            "CIFAR10_Batch412-0.644.hdf5  CIFAR10_Batch428-0.779.hdf5\r\n",
            "CIFAR10_Batch414-0.692.hdf5  CIFAR10_Batch430-0.797.hdf5\r\n",
            "CIFAR10_Batch415-0.581.hdf5  CIFAR10_Batch436-0.836.hdf5\r\n",
            "CIFAR10_Batch419-0.606.hdf5  datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fDJdQS0zzoqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "3018e3b7-731b-46cd-9126-cf9a71210c41"
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CIFAR10_Batch402-0.276.hdf5  CIFAR10_Batch420-0.732.hdf5\r\n",
            "CIFAR10_Batch403-0.485.hdf5  CIFAR10_Batch421-0.611.hdf5\r\n",
            "CIFAR10_Batch404-0.484.hdf5  CIFAR10_Batch424-0.735.hdf5\r\n",
            "CIFAR10_Batch408-0.570.hdf5  CIFAR10_Batch425-0.638.hdf5\r\n",
            "CIFAR10_Batch409-0.564.hdf5  CIFAR10_Batch426-0.751.hdf5\r\n",
            "CIFAR10_Batch412-0.644.hdf5  CIFAR10_Batch428-0.779.hdf5\r\n",
            "CIFAR10_Batch414-0.692.hdf5  CIFAR10_Batch430-0.797.hdf5\r\n",
            "CIFAR10_Batch415-0.581.hdf5  CIFAR10_Batch436-0.836.hdf5\r\n",
            "CIFAR10_Batch419-0.606.hdf5  datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E1oFkwbsdfzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a0e7621-6f96-4b57-c279-57b70a6c98b8"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"CIFAR_exp_32F.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tjQTqE-VdjjS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('CIFAR_exp_32F.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxPGleYAnVuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acc4e5b1-0909-4bfb-b4e6-efa43af50fce"
      },
      "cell_type": "code",
      "source": [
        "# Saving using PyDrive to google drive\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'DNST_model40_45.h5'})\n",
        "uploaded.SetContentFile('DNST_model40_45.h5')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "#downloaded = drive.CreateFile({'id': uploaded.get('id')})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 17WSS58RK1BlM_OdTMTK98G_Nq38t5tHl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T2HpYwzKwG6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Loss Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}